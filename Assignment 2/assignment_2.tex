\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}


\graphicspath {}


\title{Networks and Random Processes Assignment 2}
\author{Charlie Pilgrim - 1864704}
\date{October 2018}

\begin{document}

\maketitle


\section{Kingman's Coalescent}

\subsection{A}

$N_t$ is the number of particles at time t with $N_0=L$. The process $(N_t : t \geq 0)$ has the state space $\{1,...,L\}$

\subsubsection{Transition Rate of the process}

$$r(n,n-1) = {L\choose 2} \, , \, n \geq 2$$

QUESTION - WHAT ABOUT SAME STATE?
$r(n,n) = $

QUESTION - WHAT ABOUT OTHER STATES - HOW TO WRITE IT?
$r(n, y) = \, , \, y \neq n,n-1$

\subsubsection{Generator}

This is a jump process, so the generator is

$$(\mathcal{L}f)(x) = \int_{\Re} r(x,y)[f(y)-f(x)]dy$$

For this process

$$(\mathcal{L}f)(n) = r(n,n-1)(f(n-1)-f(n))$$

$$(\mathcal{L}f)(n) = {n\choose 2} (f(n-1)-f(n))$$

\subsubsection{Master Equation}

The master equation is

$$\frac{d}{dt} \pi_t(n) = \pi_t(n+1)r(n+1,n) - \pi_t(n)r(n,n-1)$$

$$\frac{d}{dt} \pi_t(n) = \pi_t(n+1){n+1\choose 2} - \pi_t(n) {n \choose 2}$$

QUESTION - IS THIS RIGHT?
QUESTION - IS THE NOTATION OKAY?
QUESTION - WHAT ABOUT EDGES? 


\subsubsection{Ergodicity}

The process is ergodic.

\subsubsection{Absorbing States}

The unique absorbing state is $N = 1$.

\subsubsection{Stationary Distributions}

Let a distribution $\pi = [N=1, N=2,... ,N=L]$

The unique stationary distribution is 

$$\pi_0 = [1,0,...,0]$$


\subsection{B - Mean Time to Asorption}

The rate of coalescence, ie moving to the next state, for each state is

$$\lambda_n = r(n,n-1) = {n\choose 2} = \frac{n(n-1)}{2}$$

The times in each state are expnentially dsitributed as

$$f_t(n) = {n \choose 2} e^{-{n \choose 2}t}$$

The expected time in each state, or the waiting time, is given by 

$$\beta_n = \dfrac{1}{\lambda_n} = \frac{2}{n(n-1)}$$

The expected time to absorption is the sum of the expected waiting times in each of the states

$$E(T) = \sum_{n=2}^L\frac{2}{n(n-1)}$$

Bringing the 2 outside of the summand and splitting up into partial fractions

$$E(T) = 2\sum_{n=2}^L\frac{1}{n-1} - \frac{1}{n}$$


$$E(T) = 2(\frac{1}{1}-\frac{1}{2}+\frac{1}{2}-\frac{1}{3} + \frac{1}{3} + ... - \frac{1}{L-1} + \frac{1}{L+1} - \frac{1}{L})$$

All but the first and last terms cancel giving

$$E(T) = 2(1 - \frac{1}{L})$$


\subsection{C - Rescaled process}

Rescale the process to $N_t/L$

$$(\mathcal{L}^Lf)(n/L) = \frac{1}{L} {n\choose2} (f(\frac{n-1}{L}) - f(\frac{n}{L}))$$

Taylor expand and let $x=\frac{n}{L}$:

$$(\mathcal{L}^Lf)(x) = \frac{1}{L}\frac{n(n-1)}{2} (f(x) - \frac{1}{L}f'(x) + \frac{1}{L^2}f''(x) + O(\frac{1}{L^3}) - f(x))$$

Cancel terms, substitute $n=Lx$ and rearrange

$$(\mathcal{L}^Lf)(x) = (\frac{x^2}{2} - \frac{x}{2L})(- f'(x) + \frac{1}{L}f''(x) + O(\frac{1}{L^2}))$$

$$\lim_{L \to \infty} (\mathcal{L}^Lf)(x) = \frac{-x^2}{2}f'(x)$$



QUESTION - STATE SPACE?
QUESTION - INITIAL CONDITION?


\subsubsection{Deterministic}

The generator has no diffusion term, only drift. So there is no variance in the process and it must be entireley deterministic. 

WHAT IS THE CALCAULTION FOR $X_T$?



\subsection{D - Simulations}

QUESTION - WHAT IS THE ADD THIS LINE BIT OF CODE IN EMMA'S WORKBOOK

\section{Ornstein-Uhlenbeck process}

\subsection{A}

The mean:

$$\frac{dm}{dt} = \frac{d}{dt}E(X_t) = E(-\alpha X_t) = -\alpha E(X_t)$$

$$\frac{dm}{dt} = -\alpha m(t)$$

$X_t^2$:

$$\frac{d}{dt}E(X_t^2) = E(- \alpha 2X_t^2 + \sigma^2)$$

$$\frac{d}{dt}E(X_t^2) = -2 \alpha E(X_t^2) + \sigma^2$$

The variance:

$$v(t) = E(X_t^2) -m(t)^2$$

$$\frac{dv}{dt} = \frac{d}{dt}E(X_t^2) - 2m\frac{dm}{dt}$$

$$\frac{dv}{dt} = -2 \alpha E(X_t^2) + \sigma^2 + 2m^2$$

\subsection{B}

\subsubsection{Solution of $m(t)$}

Solving for m(t), and considering the initial conditions, $c=x_0$

$$m(t) = x_0 e^{-\alpha t}$$

\subsubsection{Solution of $v(t)$}

Solving for v(t)

$$\frac{dv}{dt} = -2 \alpha (v + m^2) + \sigma^2 + 2 \alpha m^2$$

$$\frac{dv}{dt} +  2 \alpha v = \sigma^2$$

Homogenous solution:

$$v_hom = c_2 e^{-2 \alpha t}$$

Particular solution:

$$v_part = \frac{\sigma^2}{2 \alpha}$$

Full solution:

$$ v(t) = c_2 e^{-2 \alpha t} + \frac{\sigma^2}{2 \alpha}$$

From initial conditions, $v(0) = 0$:

$$ v(t) = \frac{\sigma^2}{2 \alpha}(1-e^{-2 \alpha t})$$

\subsubsection{Distribution}

As a Gaussian process, the distribution is fully described by the mean and variance.

$$f(X_t) = \dfrac{1}{\sqrt{\frac{2 \pi \sigma^2 (1-e^{-2 \alpha t})}{2 \alpha}}}exp(\frac{- \alpha (x - x_0 e^{- \alpha t})^2}{\sigma^2 (1-e^{-2 \alpha t})}$$

IS THAT RIGHT?

\subsubsection{Stationary Distribution}

Given enough time, the process will converge to a Gaussian stationary distribution.  

$$\lim_{t \to \infty} m(t) = 0$$

$$\lim_{t \to \infty} v(t) = \frac{\sigma^2}{2 \alpha}$$

The stationary distribution is $\sim N(0,\frac{\sigma^2}{2 \alpha})$ 

$$f_0(X_t) = \dfrac{1}{\sqrt{\frac{\pi \sigma^2}{\alpha}}}exp(\frac{- \alpha x^2}{\sigma^2})$$

CHECK IF THAT IS RIGHT

\subsection{Simulation}

\begin{figure}[H]
\includegraphics[scale=0.25]{ou_process_a.png} 
\caption{The Ornstein-Uhlenbeck process with $\alpha=1$, $\sigma^2=1$ and $X_0 = 5$. Simulated for 10 seconds with timsteps $\Delta t =0.1$ and $0.01$}
\label{fig:ou_process}
\end{figure}

Figure \ref{fig:ou_process} shows the Ornstein-Uhlenbeck process simulated. The process begins at $X_0=5$, and expereinces a "force" pulling it towards zero. As time progresses, the process moves towards $X_t=0$ and the noise term begins to dominate the behaviour. Both choices of timestep give a similar result.

\section{Moran Model and Wright-Fisher diffusion}

\subsection{A}

\subsubsection{State space}

Let the total possible L types be 

$$T = \{1,2,...,L\}$$

Each of the L individuals can have any of those types, so the state space is 

$$S = \{1,2,3,...,L\}^L$$

\subsubsection{Irreducibility}

It is not irreducible because there are absorbing states. 

\subsubsection{Stationary distributions}

The absorbing states are where all individuals have the same type

$$x_k = [k,k,...,k] \quad \forall k \in \{1,2,...,L\}  $$

The stationary distributions are any linear combination of the absorbing states that sum to 1. 

$$\pi(y) = \sum_{k=1}^L \alpha_k \pi_k(y)$$

$$\sum_{k=1}^L \alpha_k = 1$$

The coefficients, $\alpha_k$, are determined by the initial conditions and can be thought of as the probability of each type "winning" and taking over all individuals. 

\subsection{B}

\subsubsection{Markov process}

$N_t : t \geq 0$ is a Markov process. It's future distribution is determined only by it's current state, not the specific history.

\subsubsection{State space}

Each type can have any integer between 0 and L types, and there are L types, so the state space is 

$$S = \{0,1,2,...,L\}^L$$

\subsubsection{Generator}

For each type, we assume that the number of individuals of that type, $n$, can only increase and decrease by 1 at one moment in time, i.e only one event happens at a time. The rates of gain and loss can be described as:

$$r(n,n+1) = \frac{n(L-n)}{L-1}$$

$$r(n,n-1) = \frac{n(L-n)}{L-1}$$

These are symmetrical. 

??? WHERE TO GO FROM HERE???


\subsubsection{Irreducibility}

The process is not irreducible because there are absorbing states. 

\subsubsection{Stationary dsitributions}

The absorbing states are where one type has $N_k = L$ and the rest $N_k=0$. i.e

$$ \pi_k(y) = \delta_{y,k} = \begin{cases}
L \quad , \quad y=k\\
0 \quad , \quad \text{otherwise}\\
\end{cases}$$

?? IS THAT RIGHT? 
 
\subsubsection{Limiting distribution}

As $t \to \infty$ with initial condition $N_0 = 1$, the limiting distribution is

$$ [\frac{L-1}{L},0,0,...,0,\frac{1}{L}]$$










\subsection{C}

\subsection{D}

\subsection{E}

\subsection{F}



\end{document}





